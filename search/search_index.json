{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Go Full","text":"<p>Go Full is a full-stack project boilerplate template, learning tool, and reference implementation demonstrating a variety of development patterns and practices.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>In the movie, Ratatouille, the late Chef Gusteau has a saying that serves as a core theme of the film; \"anyone can cook\". Recently, AI Coding, Vibe Coding, and the like, have taken off and shifted the pardigm of development toward extremely fast, hands-off, AI developing AI, and various other rabbit holes. Ironically, the concepts and capabilities that AI Code Generation promise aren't necessarily all that new... code generation tools have been around since, well forever, as have low-code or no-code tools. At the end of the day, what matters most is the adoption, value, and functionality of the system being developed, along with the maintainability of the code that makes up the system.</p> <p>Many higher level tools take away flexibility (and the fun) of development. Oftentimes, complex packages and libraries can abstract away an understanding of what/how/why the system does what it does. This project intends not to abstract away core functinality with light and intentional usage of more basic packages (not fully functional highly opinionated frameworks).</p> <p>This project aims to provide a well-formed, \"just enough\" featured, minimalist boilerplate examplar under the idea that \"anyone can code\". And with that, we don't want to just spit out code that works (or looks like it works) as quickly as tokens could possibly be consumed, we instead focus on providing the components and resources to develop applications or services in a manner that prioritizes developers truly understanding the why, what, and how behind the things they are developing and making industry terminolgy and Buzzwords more real. We leverage code generation tools (mockery, oapi code generators, sqlc) to reduce boilerplate code development. Regardless of what is developed by hand or machine utilizing this project, the intent is to prioritize code quality over quantity, or more commonly, Clean Code along with Product quality.</p>"},{"location":"#priorities-decision-criteria","title":"Priorities &amp; Decision Criteria","text":"<ul> <li>Anyone can code</li> <li>Code and Feature Quality</li> <li>Go as a first class citizen</li> <li>Development focus and emphasis should be on the domain logic and user features</li> <li>Development should be fun!</li> <li>Semantic &amp; Idiomatic code and tools</li> <li>Tools should be configuration-based via yaml</li> <li>Languages should be typesafe</li> <li>Everything as code</li> <li>not overengineered, but smart and scalable</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>[!WARNING] This project has only been tested for development on macOS</p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<ul> <li>Git</li> <li>Make</li> <li>Docker</li> <li>Docker Compose</li> <li>Brew</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone https://github.com/cooperlutz/go-full.git\n\n# Change directory to the project folder\ncd go-full\n\n# run make init to initialize and run the project\nmake init\n</code></pre> <p>Then open your browser to <code>http://app.lvh.me</code> to see the running application</p>"},{"location":"#additional-helpful-development-commands","title":"Additional Helpful Development Commands","text":"<pre><code>make # end to end development tools\n\nmake compose # builds, deploys, and runs development environment\n\nmake commit # provides a mechanism to simplify conventional commits\n</code></pre> <p>For further details, please consult our docs</p>"},{"location":"system/","title":"System Architecture","text":""},{"location":"system/#full-stack","title":"Full Stack","text":"<p>This project exemplifies a full stack system architecture inclusive of a frontend User Interface (UI), a backend Application Programming Interface (API) encompassing the core logic, and a data persistence layer.</p> <p></p>"},{"location":"system/#domain-driven-design","title":"Domain-Driven Design","text":"<p>This project adopts and adheres to the Domain-Driven Design approach. Our bounded contexts are implemented as modules within the system. Each module adheres to the principles and patterns outlined in DDD, including domain entities, infrastructure repositories, and application services. Module implementations enable loose coupling of system components and an ability to easily extract modules into their own services if necessary. Further, each module is designed to enable the system to implement inversion of control and dependency injection principles.</p>"},{"location":"system/#further-ddd-reading","title":"Further DDD Reading","text":"<ul> <li>DDD Reference</li> <li>DDD Burger: A good article, particularly referencing DDD in Go, that I think does a nice job reflecting the various layers as if we were building a hamburger.</li> </ul>"},{"location":"system/#modular-monolith","title":"Modular Monolith","text":"<p>ARE YOU KIDDING ME? WHERE ARE THE MICROSERVICES???? Yeah yeah yeah... well first and foremost, you could think of this project itself as a microservice... but more imporantly, that's not the intent of this project. This project intends to focus on developing a well formed full stack system in an easy to understand / learn / develop manner, and introducing microservices would exponentially complicate things. If you would prefer a series of microservices, you can easily separate the SPA and create a series of services leveraging this project as a starting point.</p> <p></p>"},{"location":"system/#event-driven","title":"Event-Driven","text":"<p>The system provides capabilities to support event-driven architecture patterns through the use of an event bus in the form of PostgreSQL tables. This is facilitated via implementation of the Watermill framework. Read more about the decision: ADR-00005</p> <p>In order to reduce Direct dependency on Watermill, the eeventdriven package is provided to abstract away the Watermill implementation details from the rest of the system. This allows for easier swapping of the underlying api in the future, if desired.</p> <p>The below Component Diagram illustrates how the event-driven components are integrated into the overall system architecture.</p> <p></p>"},{"location":"system/#mono-repo-project-layout-structure","title":"Mono Repo Project Layout / Structure","text":"<p>This project is intentionally structured as a monorepo to display how all of the various pieces of the system are stitched together. We can follow the logical flow of the system from frontend view all the way through the backend database queries and every layer in between.</p> <p>Given the core of the system is defined in Go, we adhere to commonly accepted Go project layout best practices with slight adaptations to suit our needs.</p> <ul> <li>Directory Structure Reference Point: https://github.com/golang-standards/project-layout</li> </ul> <p>Root Directory Layout:</p> <pre><code>\u251c\u2500\u2500 api # api\n\u251c\u2500\u2500 app # core application implementation\n\u251c\u2500\u2500 build # build files (dockerfiles)\n\u251c\u2500\u2500 cmd # primary commands for running the application\n\u251c\u2500\u2500 configs # configuration files\n\u251c\u2500\u2500 db # database code (migrations, queries, etc.)\n\u251c\u2500\u2500 deploy # deploy targets\n\u251c\u2500\u2500 docs # documentation site and content\n\u251c\u2500\u2500 examples # example code\n\u251c\u2500\u2500 internal # core logic\n\u251c\u2500\u2500 pkg # go packages, cross-cutting\n\u251c\u2500\u2500 test # e2e tests and test utilities\n\u251c\u2500\u2500 tools # tools for the project\n\u2514\u2500\u2500 vendor # vendor packages  https://go.dev/ref/mod#vendoring\n</code></pre>"},{"location":"system/#frontend-vue-layout","title":"Frontend Vue Layout","text":"<p>The frontend application is defined as an embedded SPA, written in Vue.js, the project layout for the frontend vue application follows the pattern defined here Vue Reference</p>"},{"location":"system/frontend_ui/","title":"Frontend User Interface (UI)","text":""},{"location":"system/frontend_ui/#frontend-user-interface","title":"Frontend / User Interface","text":"<p>ADR Ref: ADR-00005</p> <p>The Frontend (User Interface) is implemented as a Single-Page Application (SPA) developed in Vue. The frontend application code can be found in <code>/api/frontend</code> intentionally because following our goal to align the overall project to be semantic and idiomatic... the frontend web ui is really just an interface in the context of the overall system.</p> <p>The Vue application is compiled, then the compiled frontend is embedded within the Go application. this can be seen within <code>api/frontend/frontend.go</code>.</p> <p>Note: when Go compiles it looks for <code>.go</code> files and ignores anything else, therefore, the all of the Vue/Typescript/node_modules/etc. have no impact to Go compilation</p> <p>Vite is simply used for building and development.</p>"},{"location":"system/frontend_ui/#design-system","title":"Design System","text":"<p>ADR Ref: ADR-00006</p>"},{"location":"system/module/","title":"System Modules","text":"<p>As noted in ADR-00002, the system architecture adopts a modular monolith approach, adhering to principles of Domain-Driven Design (DDD).</p>"},{"location":"system/module/#architecture-styles","title":"Architecture Styles","text":"<p>Individual modules are given freedom to choose their architectural style, however, we encourage the adoption of Clean Architecture or Hexagonal Architecture styles to ensure separation of concerns and promote maintainability.</p>"},{"location":"system/module/#clean-architecture","title":"Clean Architecture","text":"<p>The module is structured into distinct layers, each with specific responsibilities:</p> <ul> <li>Domain Layer: Contains the core business logic and domain entities. This layer is independent of any external systems or frameworks.</li> <li>Application Layer: Contains application services that orchestrate domain logic and handle use cases.</li> <li>Interface Layer: Contains the API controllers and routes that handle incoming requests and responses.</li> <li>Infrastructure Layer: Contains implementations for data access, external services, and other infrastructure concerns</li> </ul> <p></p> <p>Reference Module: Exam Library</p>"},{"location":"system/module/#hexagonal-architecture","title":"Hexagonal Architecture","text":"<p>The module is designed around the concept of ports and adapters, allowing for flexibility and easy integration with external systems:</p> <ul> <li>Core Domain: Contains the business logic and domain entities.</li> <li>Ports: Define interfaces for communication between the core domain and external systems.</li> <li>Adapters: Implement the ports to interact with external systems such as databases, APIs, and user interfaces.</li> </ul> <p></p> <p>Reference Module: Examination     - Based on ThreeDotLabs' interpretation via Wild Workouts</p>"},{"location":"system/module/#module-structure","title":"Module Structure","text":"<p>Each system module is structured to encapsulate the various layers of the application, ensuring separation of concerns and maintainability. The typical structure of a module is as follows:</p>"},{"location":"system/module/#core-backend","title":"core / backend","text":"<pre><code>internal/DOMAIN_MODULE\n\u251c\u2500\u2500 api          # Interface Layer: API controllers and routes\n\u251c\u2500\u2500 app          # Application Layer: Application services and use cases\n\u251c\u2500\u2500 domain       # Domain Layer: Core business logic and domain entities\n\u251c\u2500\u2500 infra        # Infrastructure Layer: Data access and external services\n\u2514\u2500\u2500 DOMAIN_MODULE.go  # Module definition and entry point\n</code></pre>"},{"location":"system/module/#mock-implementations","title":"Mock Implementations","text":"<pre><code>test/mocks/DOMAIN_MODULE/\n</code></pre> <p>In order to configure the relevant mock implementations for use within tests, each system module will require updates to the <code>.mockery</code> configuration file to outline relevant system module packages.</p>"},{"location":"system/module/#frontend","title":"frontend","text":"<pre><code>api/frontend/src/DOMAIN_MODULE\n\u251c\u2500\u2500 __tests__   # Tests specific to the module\n\u251c\u2500\u2500 assets       # Assets specific to the module\n\u251c\u2500\u2500 components   # Vue components specific to the module\n\u251c\u2500\u2500 composables  # Vue composables specific to the module\n\u251c\u2500\u2500 configs      # Configuration files specific to the module\n\u251c\u2500\u2500 layouts      # Vue layouts specific to the module\n\u251c\u2500\u2500 router      # Vue router definitions specific to the module\n\u251c\u2500\u2500 services     # Services (API clients) specific to the module\n\u251c\u2500\u2500 stores        # Vuex store modules specific to the module\n\u251c\u2500\u2500 styles       # Styles specific to the module\n\u251c\u2500\u2500 utils       # Utility functions specific to the module\n\u251c\u2500\u2500 views        # Vue views specific to the module\n\u2514\u2500\u2500 DOMAIN_MODULE.ts  # Module definition and entry point\n</code></pre>"},{"location":"system/module/#rest-api","title":"REST API","text":"<pre><code>api/rest/DOMAIN_MODULE/{version}\n\u251c\u2500\u2500 client # Generated API client for the individual module version\n\u2502   \u251c\u2500\u2500 cfg.yaml # Configuration for the individual module version server\n\u2502   \u251c\u2500\u2500 client.gen.go # Generated client code for the individual module version\n\u2502   \u2514\u2500\u2500 generate.go # Code generation script for the individual module version\n\u251c\u2500\u2500 server # Generated API server for the individual module\n\u2502   \u251c\u2500\u2500 cfg.yaml # Configuration for the individual module version server\n\u2502   \u2514\u2500\u2500 generate.go # Code generation script for the individual module version\n\u2514\u2500\u2500 api.yaml # OpenAPI specification for the individual module version\n</code></pre>"},{"location":"system/module/#database","title":"Database","text":"<p>Note: Migration files must be defined within a consolidated <code>db/migrations/</code> directory to ensure proper execution order during migration runs.</p>"},{"location":"system/module/#migrations","title":"Migrations","text":"<pre><code>db/migrations/ # Database migration files\n</code></pre>"},{"location":"system/module/#queries-and-schemas","title":"Queries and Schemas","text":"<pre><code>db/DOMAIN_MODULE\n\u251c\u2500\u2500 queries  # Database query files specific to the module\n\u2514\u2500\u2500 schemas  # Database schema files specific to the module\n</code></pre> <p>Additionally, each system module will require updates to the corresponding <code>.sqlc</code> file to outline the relevant configuration.</p>"},{"location":"system/workflow/","title":"System Development Workflow","text":"<p>The workflow associated with this project aims to prioritize feature development, code quality, and continuous integration and deployment. The following pseudo Value Stream Map illustrates the overall workflow:</p> <p></p>"},{"location":"system/workflow/#dora-metrics","title":"DORA Metrics","text":"<p>DORA Metrics can be used to measure the performance of software development teams. The four key metrics are:</p> <ol> <li>Lead Time for Change: The time it takes to go from code committed to code successfully running in production.</li> <li>Deployment Frequency: How often an organization successfully releases to production.</li> <li>Change Failure Rate: The percentage of changes that result in a failure in production.</li> <li>Time to Restore Service: How long it takes to recover from a failure in production.</li> </ol> <p>In order to measure our development performance, a self-assessment based on the DORA (DevOps Research and Assessment) Quick Check has been conducted. View the results of the assessment here.</p>"},{"location":"system/decisions/","title":"Decisions (ADRs)","text":"<p>We document decisions as Architecture Decision Records, leveraging the format as defined and popularized by Michael Nygard. However, we are interpreting and adapting the concept of ADRs beyond strictly architecture, and making documented decisions inclusive of implementations and / or other relevant decisions that are worthy of documenting. ADRs provide a simple and concise format and its generally good practice to document decisions and the decision making process in just about any context.</p> <p>We have also adapted the base ADR template to better suit our needs. See below for the adapted template we use.</p>"},{"location":"system/decisions/#adr-template","title":"ADR Template","text":"<pre><code># [00000]: Title of the Decision\n\n## Status\n\n[e.g., Proposed, Accepted, Rejected, Deprecated, Superseded by ADR-XXX]\n\n## Context\n\nDescribe the issue or problem that prompted this architectural decision. What are the driving forces, requirements, or constraints that led to the need for a decision?\n\n## Decision\n\nClearly state the chosen architectural decision. Explain what was decided and why this specific option was chosen.\n\n### Implementation\n\nIf applicable, outline relevant implementation decisions, steps, or considerations that arise from this architectural decision, along with supporting considerations to support the decision.\n\n## Alternatives Considered\n\nList and briefly describe the alternative options that were explored but ultimately not selected. Provide a brief rationale for why each alternative was rejected.\n\n## Consequences\n\nDetail the implications of this decision. What are the positive and negative impacts? What becomes easier or more difficult as a result of this change? Consider impacts on development, operations, maintenance, performance, security, and other relevant aspects.\n</code></pre>"},{"location":"system/decisions/00001_core/","title":"00001: Core Logic","text":""},{"location":"system/decisions/00001_core/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00001_core/#context","title":"Context","text":"<p>Within the context of the overall system being developed, a programming language is required to support our core logic and the application implementation of the system.</p>"},{"location":"system/decisions/00001_core/#decision","title":"Decision","text":"<p>Go will be used as the programming language for the core logic and application implementation of the system.</p>"},{"location":"system/decisions/00001_core/#alternatives-considered","title":"Alternatives Considered","text":"<p>None.</p>"},{"location":"system/decisions/00001_core/#consequences","title":"Consequences","text":"<p>The decision to use Go will have several consequences:</p> <ul> <li>Performance: Go is known for its high performance, especially with concurrency support through goroutines</li> <li>Type Safety: Go is a statically typed language, which helps catch errors at compile time and improves code reliability.</li> <li>Simplicity: Go's syntax is simple and easy to understand, which will help in maintaining the codebase and onboarding new developers.</li> <li>Community: Go has a strong and active community, which means we can easily find support, resources, and best practices.</li> </ul>"},{"location":"system/decisions/00002_system_arch/","title":"00002: System Architecture","text":""},{"location":"system/decisions/00002_system_arch/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00002_system_arch/#context","title":"Context","text":"<p>In context of developing the system, a general architectural approach needs to be defined. This decision will guide the overall project development.</p>"},{"location":"system/decisions/00002_system_arch/#decision","title":"Decision","text":"<p>The chosen architectural decision is to adopt a modular monolith architecture, adhering to principles of Domain-Driven Design (DDD).</p>"},{"location":"system/decisions/00002_system_arch/#implementation","title":"Implementation","text":"<ul> <li>System Modules will be defined based on bounded contexts identified through Domain-Driven Design practices.</li> <li>Each module will be encapsulated across each layer of the application (e.g., presentation, application, domain, infrastructure) and be capable of being extended, removed, or replaced with minimal impact to other modules.</li> </ul>"},{"location":"system/decisions/00002_system_arch/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Microservices: While microservices offer scalability and independent deployment, they introduce significant complexity in terms of inter-service communication, data consistency, and operational overhead. Given the current project scope, this complexity is unwarranted.</li> </ul>"},{"location":"system/decisions/00002_system_arch/#consequences","title":"Consequences","text":"<p>If the system were to need improved scalability, highly complex logic within an individual module, or require independent deployment cycles for different parts of the system, a shift to microservices architecture may be reconsidered.</p>"},{"location":"system/decisions/00003_data_persistence/","title":"00003: Data Persistence","text":""},{"location":"system/decisions/00003_data_persistence/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00003_data_persistence/#context","title":"Context","text":"<p>In the context of the overall system, persistent data storage will be required to store data. This decision influences and directly impacts development complexity, tooling, and system performance.</p>"},{"location":"system/decisions/00003_data_persistence/#decision","title":"Decision","text":"<p>The chosen approach for data persistence is to use a relational database management system (RDBMS) for structured data storage, leveraging its ACID properties to ensure data integrity and consistency. This decision was made to align with the project's requirements for complex querying and reporting.</p>"},{"location":"system/decisions/00003_data_persistence/#implementation","title":"Implementation","text":"<ul> <li>Database Schema Design: The database schema will be designed to reflect the domain model, ensuring that tables and relationships align with the application's requirements. Each module will have its own schema to encapsulate its data.</li> <li>ORM Usage: An Object-Relational Mapping (ORM) tool will NOT be used. Instead, direct SQL queries will be employed to interact with the database, providing greater control over query optimization and performance tuning. These queries will be defined and generated via sqlc</li> <li>PostgreSQL has been selected as the specific RDBMS.</li> </ul>"},{"location":"system/decisions/00003_data_persistence/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"system/decisions/00003_data_persistence/#storage-options","title":"Storage Options","text":"<ul> <li>NoSQL Databases: While NoSQL databases offer flexibility in handling unstructured data and can scale horizontally, they may lack the robust transactional support required for this project. Given the current data requirements, the complexity introduced by NoSQL systems is not justified.</li> <li>In-Memory Databases: Although in-memory databases provide high-speed data access, they are not suitable for long-term data persistence due to volatility.</li> <li>Flat File Storage: While flat file storage is simple to implement, it lacks the advanced querying capabilities and data integrity features provided by RDBMS. This option was rejected due to scalability and performance concerns.</li> </ul>"},{"location":"system/decisions/00003_data_persistence/#database-management-systems","title":"Database Management Systems","text":"<ul> <li>SQLite: While SQLite is lightweight and easy to set up, it is not suitable for applications requiring concurrent access by multiple users or high transaction volumes. Further, it would limit future scalability options.</li> </ul>"},{"location":"system/decisions/00003_data_persistence/#consequences","title":"Consequences","text":"<p>As a consequence of this decision:</p> <ul> <li>Increased complexity to maintain the postgres database server</li> <li>Need to manage database migrations and versioning</li> <li>Improved data integrity and consistency</li> </ul>"},{"location":"system/decisions/00004_frontend/","title":"00004: Frontend User Interface (UI)","text":""},{"location":"system/decisions/00004_frontend/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00004_frontend/#context","title":"Context","text":"<p>In order for the project to be considered a \"full stack\", a user interface is a necessity</p>"},{"location":"system/decisions/00004_frontend/#decision","title":"Decision","text":"<p>The Frontend UI will be developed as a Single Page Application in Vue and compiled to a SPA, which is ultimately embedded in Go. Further, we will aim to minimize the amount of javascript/typescript code utilized in the development of the frontend.</p> <p>This decision was made based on the following considerations:</p> <ul> <li>Vue is lightweight and more easily translated to another framework if needed.</li> <li>Vue has a smaller learning curve compared to React</li> <li>Vue's Templates are more HTML centric</li> <li>Vue can utilize React components, if desired.</li> <li>Vue can utilize basic HTML/CSS/JS if desired.</li> <li>Utilizing openapi-generator we can define an openapi specification and generate the a typescript client that the frontend can consume and expose within Vue composables.</li> </ul>"},{"location":"system/decisions/00004_frontend/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>HTML Templates w/ HTMX: Go's html/template package could be utilized to render server side HTML templates. However, unless we were to utilize and implement HTMX a fair amount of JavaScript would be required to achieve the desired interactivity. Further, there are far fewer points of reference and examples for this approach.</li> <li>Vue w/ Nuxt SSR: this solution would require additional java/typescript code which we are trying to minimize.</li> <li>React SPA: React can get bloated and requires a significant amount of java/typescript, which we are trying to minimize.</li> </ul>"},{"location":"system/decisions/00004_frontend/#consequences","title":"Consequences","text":"<ul> <li>additional development effort will be required in order to handle integrations between the frontend and backend</li> <li>A programmatic client will need to be developed to support communication between the frontend and backend</li> </ul>"},{"location":"system/decisions/00005_programming_interface/","title":"00005: Initial Application Programming Interface","text":""},{"location":"system/decisions/00005_programming_interface/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00005_programming_interface/#context","title":"Context","text":"<p>In order to enable programmatic access to the core / backend, an interface needs to be exposed.</p>"},{"location":"system/decisions/00005_programming_interface/#decision","title":"Decision","text":"<p>The initial programming interface will be a RESTful API adhering to OpenAPI specifications. The OpenAPI specification will be utilized to generate go server code for the backend, go client code which can be used for e2e tests and other go based clients, and a typescript client which can be used by the frontend.</p>"},{"location":"system/decisions/00005_programming_interface/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>GraphQL</li> <li>gRPC</li> </ul>"},{"location":"system/decisions/00005_programming_interface/#consequences","title":"Consequences","text":"<p>The OpenAPI specification will need to be maintained as the system evolves. The OpenAPI specification will drive much of the development of the system as it will be used to generate significant portions of code for both the backend and frontend.</p>"},{"location":"system/decisions/00006_base_design_system/","title":"00006: Design System Basis","text":""},{"location":"system/decisions/00006_base_design_system/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00006_base_design_system/#context","title":"Context","text":"<p>For the purposes of the frontend user interface, a component &amp; styling is required.</p>"},{"location":"system/decisions/00006_base_design_system/#decision","title":"Decision","text":"<p>TailwindCSS along with DaisyUi were chosen to serve as the basis for the design system. TailwindCSS has a strong ecosystem and many readily available reference points to support frontend development.</p> <p>DaisyUi has gained a strong following and is incredibly semantic in nature. DaisyUi is also highly portable if the frontend were to be ported to React / HTML / svelte / other. DaisyUi also provides the ability to extend, override, or ignore syling of various components or themes as needed.</p>"},{"location":"system/decisions/00006_base_design_system/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Shadcn: while incredibly popular, if not currently the most popular, shadcn requires a fair amount of java/type scripting and is heavily react centric.</li> <li>Vuetify: is more complex and vue centric, making portability more difficult.</li> <li>PrimeVue: is more complex and vue centric, making portability more difficult.</li> <li>Material: Material Design has a strong following, but its implementation can be verbose and may not fit well with the desired aesthetic.</li> <li>Bootstrap: while widely used and easy to implement, Bootstrap's default styles may not provide the level of customization needed for the project.</li> </ul>"},{"location":"system/decisions/00006_base_design_system/#consequences","title":"Consequences","text":"<ul> <li>Developers will need to familiarize themselves with TailwindCSS and DaisyUi conventions.</li> <li>The design system will be more easily portable to other frontend frameworks if needed in the future.</li> </ul>"},{"location":"system/decisions/00007_releases/","title":"00007: Releases","text":""},{"location":"system/decisions/00007_releases/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00007_releases/#context","title":"Context","text":"<p>In the context of releasing code, a mechanism to track and document releases is essential. This decision outlines the approach for managing releases, including versioning, changelogs, and distribution methods.</p>"},{"location":"system/decisions/00007_releases/#decision","title":"Decision","text":"<p>The decision is to adopt semantic versioning (SemVer) for versioning, maintain a detailed changelog in the repository, and use Git tags to mark release points. Release distributions and packages will be managed via Github Releases.</p>"},{"location":"system/decisions/00007_releases/#implementation","title":"Implementation","text":"<ul> <li>Commitizen will handle conventional commit messages to automate versioning and changelog generation.</li> <li>GoReleaser will be used to automate the build and release process, ensuring consistent and reproducible releases.</li> <li>Releases will be documented in a <code>CHANGELOG.md</code> file, following the \"Keep a Changelog\" format. This will be implemented via Commitizen.</li> <li>Git tags will be created for each release, following the SemVer format (e.g., v1.0.0). Commitizen will handle tag creation.</li> <li>Github Actions will handle orchestration of the release process, integrating with GoReleaser for building and publishing releases.</li> <li>Releases will be triggered upon merging to the main branch, without utilizing release branches.</li> </ul>"},{"location":"system/decisions/00007_releases/#alternatives-considered","title":"Alternatives Considered","text":"<p>Release branches were considered and initially implemented but were ultimately removed in favor of a more streamlined approach that is more aligned to Trunk Based Development.</p>"},{"location":"system/decisions/00007_releases/#consequences","title":"Consequences","text":"<ul> <li>Development Flow is streamlined by removing the need to manage release branches, changelogs and automated versioning.</li> <li>Releases are more frequent and easier to manage, reducing overhead and complexity in the release process.</li> <li>All merges to <code>main</code> should be considered fully functional code, as they will directly trigger releases that could be consumed by end users.</li> <li>Exceptions may be required in situations when merging to main without triggering a release is required, and will need to be solutioned for.</li> </ul>"},{"location":"system/decisions/00008_dev_env/","title":"00008: Development Environment","text":""},{"location":"system/decisions/00008_dev_env/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00008_dev_env/#context","title":"Context","text":"<p>In the context of Development of the system, a consistent environment is required in order to ensure the system is reproducible.</p>"},{"location":"system/decisions/00008_dev_env/#decision","title":"Decision","text":"<p>The decision was made to utilize Docker &amp; Docker Compose on developer workstations in order to provide consistency</p>"},{"location":"system/decisions/00008_dev_env/#implementation","title":"Implementation","text":"<p>Hardware: Local Workstation Platform: MacOS Assumed Tooling: installed to local workstation via brew Deployment Configuration &amp; Orchestration: Docker Compose</p>"},{"location":"system/decisions/00008_dev_env/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Local K8s implementation (kind, minikube): these solutions would more effectively scale under the assumption that the 'production' deployment is running within a k8s cluster, however it also adds additional complexity and requires further development. Ultimately, docker compose is lighter weight and simpler to implement and suits our current needs, and enables us to shift toward a local k8s if and when the need presents itself.</li> </ul>"},{"location":"system/decisions/00008_dev_env/#consequences","title":"Consequences","text":"<ul> <li>There are limitations with utilizing Postgres in containers, which could result in issues when running the application in production database servers.</li> <li>The current solution does not provide support for Windows Desktop OS, but given a majority of functionality is containerized, support can be added at a later point in time.</li> </ul>"},{"location":"system/decisions/00009_event_driven/","title":"00009: Event Driven","text":""},{"location":"system/decisions/00009_event_driven/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00009_event_driven/#context","title":"Context","text":"<p>In the context of the system, the system must be able to respond and react to events that occur within the domain.</p>"},{"location":"system/decisions/00009_event_driven/#decision","title":"Decision","text":"<p>The decision was made to implement a mechanism (a reusable package) to support domain events and event-driven patterns, primarily and initially, pub-sub. The addition of this package and initial implementation of this solution will provide support for emitting, storing, reading, and responding to events that happen across the system.</p>"},{"location":"system/decisions/00009_event_driven/#implementation","title":"Implementation","text":"<p>Given we would like to minimize infrastructure, but maintain the ability to keep the system loosely coupled, while also keeping records of events that occur within the system, the decision has been made to utilize Postgres as the event / message store.</p> <p>The decision has been made to leverage the Watermill (Lic MIT) framework, which provide OOTB Postgres adapter along with available pubsub functionality.</p>"},{"location":"system/decisions/00009_event_driven/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Custom in-memory Event Bus. While this is easily accomplished thanks to Go's concurrency functionality and would enable us to send and receive messages across channels implemented via each domain's module, it would require additional effort to support recording and storing events.</li> </ul>"},{"location":"system/decisions/00009_event_driven/#consequences","title":"Consequences","text":"<ul> <li>We may find limitations in what postgres is able to handle which may make us look to an alternate infrastructure solution (e.g. RabbitMQ, Kafka, etc.)</li> <li>Additional network traffic will occur between the application and postgres database which may introduce performance challenges</li> <li>We become dependent on the functionality of Watermill and its development progress</li> </ul>"},{"location":"system/decisions/00010_deployment/","title":"00010: Deployment","text":""},{"location":"system/decisions/00010_deployment/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"system/decisions/00010_deployment/#context","title":"Context","text":"<p>The system should be deployable and continuously deployed to a live environment to enable iteration and support fast flow of value to end users.</p>"},{"location":"system/decisions/00010_deployment/#decision","title":"Decision","text":"<p>The decision was made to utilize Azure Public Cloud services, specifically Azure Container Apps, for deployment of the system. This decision aligns with the organization's existing cloud strategy and leverages Azure's well-architected framework to ensure reliability, security, operational excellence, performance efficiency, and cost optimization.</p>"},{"location":"system/decisions/00010_deployment/#implementation","title":"Implementation","text":"<ul> <li>The system will be containerized using Docker, allowing for consistent deployment across environments.</li> <li>Azure Container Apps will be used to host the containerized application, providing a serverless environment that automatically scales based on demand.</li> <li>Infrastructure as Code (IaC) practices will be employed, specifically, Azure Bicep, to define and manage the deployment infrastructure. Azure Bicep eliminates the need to manage and maintain IaC state files, as seen with Terraform. Further, it is a Go-centric language, making it easier for Go developers to learn and utilize.</li> </ul>"},{"location":"system/decisions/00010_deployment/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>On-Premises Deployment: While this option provides full control over the infrastructure, it introduces significant overhead in terms of maintenance, scalability, and disaster recovery.</li> <li>Other Cloud Providers (AWS, GCP): Although these providers offer similar services, the primary maintainer has more experience with Azure.</li> <li>Kubernetes Cluster: While this option provides flexibility and control, it introduces additional complexity in terms of management and maintenance compared to Azure Container Apps.</li> <li>Multi-Cloud Deployment: While this approach can enhance redundancy and availability, it introduces significant complexity in terms of management, cost, and potential latency issues.</li> <li>Fly.io or Heroku: These platforms offer simplicity and ease of use, but do not provide a representative environment for enterprise-grade applications and may limit future scalability and flexibility.</li> </ul>"},{"location":"system/decisions/00010_deployment/#consequences","title":"Consequences","text":"<ul> <li>Leveraging Azure's managed services reduces the operational burden on the development team, allowing them to focus on delivering value rather than managing infrastructure.</li> <li>If the organization decides to change cloud providers in the future, there may be migration challenges due to reliance on Azure-specific services. A portion of these challenges should be mitigated by utilizing infrastructure as code (IaC) practices as well as containerization of the application.</li> </ul>"},{"location":"system/deployment/","title":"Deployment on Azure","text":"<p>Relevant Decision Ref: ADR-00010</p>"},{"location":"system/deployment/#azure-deployment-architecture","title":"Azure Deployment Architecture","text":"<p>The architecture diagram above illustrates the deployment of the application on Microsoft Azure.</p>"},{"location":"system/deployment/#additional-documentation","title":"Additional Documentation","text":"<p>Relevant Azure Services</p> <p>Azure Well-Architected Framework</p>"},{"location":"system/deployment/azure_services/","title":"Azure Services","text":""},{"location":"system/deployment/azure_services/#subscription","title":"Subscription","text":"<p>The Azure Subscription is the top-level container for all Azure resources. It serves as a billing unit as well as a logical separation for resource management.</p>"},{"location":"system/deployment/azure_services/#resource-group","title":"Resource Group","text":"<p>The Resource Group is a container that holds related Azure resources for an Azure solution.</p>"},{"location":"system/deployment/azure_services/#azure-container-apps-environment","title":"Azure Container Apps Environment","text":"<p>The Azure Container Apps Environment provides physical and logical isolation for Container Apps.</p>"},{"location":"system/deployment/azure_services/#container-app","title":"Container App","text":"<p>The Container App encapsulates the application code and its dependencies, allowing it to run in a serverless environment.</p>"},{"location":"system/deployment/azure_services/#log-analytics-workspace","title":"Log Analytics Workspace","text":"<p>The Log Analytics Workspace is a centralized repository for collecting and analyzing log data from various Azure resources.</p>"},{"location":"system/deployment/azure_services/#azure-monitor","title":"Azure Monitor","text":"<p>Azure Monitor is a comprehensive monitoring service that provides full-stack observability across applications and infrastructure.</p>"},{"location":"system/deployment/azure_services/#application-insights","title":"Application Insights","text":"<p>Application Insights is an application performance management service that provides real-time monitoring and analytics for web applications.</p>"},{"location":"system/deployment/azure_services/#azure-database-for-postgresql-flexible-server","title":"Azure Database for PostgreSQL Flexible Server","text":"<p>The Azure Database for PostgreSQL Flexible Server is a managed database service that provides built-in high availability, automated backups, and scaling capabilities for PostgreSQL databases.</p>"},{"location":"system/deployment/azure_well_architected/","title":"Azure Well-Architected Framework","text":"<p>References for individual Azure Services:</p> <ul> <li>Azure Database for PostgreSQL</li> <li>Azure Container Apps</li> <li>Azure Log Analytics Workspace</li> <li>Application Insights</li> </ul>"},{"location":"system/deployment/azure_well_architected/#reliability","title":"Reliability","text":""},{"location":"system/deployment/azure_well_architected/#security","title":"Security","text":""},{"location":"system/deployment/azure_well_architected/#operational-excellence","title":"Operational Excellence","text":""},{"location":"system/deployment/azure_well_architected/#performance-efficiency","title":"Performance Efficiency","text":""},{"location":"system/deployment/azure_well_architected/#cost-optimization","title":"Cost Optimization","text":""},{"location":"system/development/","title":"Software Development Lifecycle","text":""},{"location":"system/development/#developing","title":"Developing","text":"<p>Exemplar Pull Requests:</p> <ul> <li>Adding a New e2e Feature</li> </ul> <p></p> <p>This diagram illustrates the ideal development workflow for contributing code to the project.</p>"},{"location":"system/development/branching/","title":"Branching Strategy","text":"<p>We follow Trunk Based Development practices, enforcing and encouraging short-lived feature branches that are continuously merged into <code>main</code> (trunk).</p> <p></p>"},{"location":"system/development/branching/#justification-context","title":"Justification &amp; Context","text":"<p>Long-lived branches can lead to significant merge conflicts, integration challenges, and delays in delivering value to end users. By adopting Trunk Based Development, we aim to minimize these issues and promote a more collaborative and efficient development process.</p> <p>Example of long-lived feature branches</p> <p>In the above example, a feature branch was created for a new feature, the exam library. Luckily, the code itself was modularized enough to avoid significant merge conflicts, along with only having an individual maintainer at the time. but the branch itself adds 9415 lines of code and 134 file changes. Imagine the amount of time and effort required to review and merge this code if multiple maintainers were working on the codebase simultaneously, or if the branch had been open for several weeks or months, and the <code>main</code> branch had diverged significantly, and the feature branch had to be rebased multiple times....</p> <p>By keeping feature branches short-lived and merging them into <code>main</code> frequently, we can reduce the risk of integration issues, ensure that code changes are reviewed and tested promptly, and maintain a high level of code quality and stability in the <code>main</code> branch.</p> <p>We treat <code>main</code> as the source of truth for production-ready code, and all changes to <code>main</code> should be treated as production-ready, thoroughly reviewed, tested, and validated before being merged.</p>"},{"location":"system/development/building/","title":"Building","text":"<p>The backend (core) application is packaged into a single binary, which references the built frontend files</p> <p>The frontend application is packaged into relevant build files utilizing Vite, output to the <code>/dist/frontend</code> directory.</p> <p>The backend application serves these files according to the logic defined within <code>/api/frontend/frontend.go</code></p> <p></p> <p>This rudimentary diagram illustrates the build flow for both the frontend and backend applications. First, the frontend application is built using Vite, producing static files in the <code>/dist/frontend</code> directory. Next, the backend application is built using Go, which includes embedding the previously built frontend files. The final output is a single binary that serves both the backend API and the frontend application. These are then built into a Docker container for deployment.</p> <p>For orchestrating the build process, GoReleaser is utilized. GoReleaser simplifies the build and release process by automating tasks such as compiling the application for multiple platforms, creating Docker images, and generating release notes. The configuration for GoReleaser is defined in the <code>.goreleaser.yml</code> file located at the root of the repository.</p>"},{"location":"system/development/committing/","title":"Committing Code","text":"<p>We use Commitizen to standardize our commit messages according to Conventional Commits.</p> <p>Commits should be made against local feature branches, and pull requests should be created to merge changes into <code>main</code>.</p> <p></p>"},{"location":"system/development/committing/#make-a-commit","title":"Make a Commit","text":"<p>In order to make a commit, simply run:</p> <pre><code>make commit\n</code></pre> <p>This <code>make</code> command will invoke Commitizen, which will prompt you for the necessary information to create a standardized commit message adhering to the Conventional Commits specification.</p>"},{"location":"system/development/environment/","title":"Development Environment","text":"<p>Relevant Decision Ref: ADR-00008</p> <p></p> <ul> <li>Nginx: Proxy &amp; Load Balancer enabling container communication and routing</li> <li>App: Compiled Go backend application container</li> <li>Database: Postgres container</li> <li>Prometheus: Metrics collection and storage</li> <li>Jaeger: Tracing collection and storage</li> <li>Mkdocs: Documentation site container</li> </ul>"},{"location":"system/development/environment/#utilizing-the-dev-environment","title":"Utilizing The Dev Environment","text":"<pre><code>make compose # builds, deploys, and runs development environment\n</code></pre> <p>Configuration files for the development environment are located in the deploy/compose directory</p> <p>The <code>make compose</code> command targets the <code>deploy/compose/docker-compose.yml</code> file, which includes the relevant service definitions for the development environment</p> <pre><code>deploy/compose/\n\u2502   \n\u251c\u2500\u2500 app # application layer\n\u2502   \u2514\u2500\u2500 docker-compose.\n\u2502   \n\u251c\u2500\u2500 database # database layer\n\u2502   \u2514\u2500\u2500 docker-compose.postgres.yml\n\u2502   \n\u251c\u2500\u2500 docs # documentation layer\n\u2502   \u2514\u2500\u2500 docker-compose.docs.yml\n\u2502   \n\u251c\u2500\u2500 network # network layer\n\u2502   \u2514\u2500\u2500 docker-compose.nginx.yml\n\u2502   \n\u251c\u2500\u2500 observability # observability layer\n\u2502   \u251c\u2500\u2500 docker-compose.jaeger.yml\n\u2502   \u2514\u2500\u2500 docker-compose.prometheus.yml\n\u2502 \n\u2514\u2500\u2500 docker-compose.yml # main compose file that ties everything together\n</code></pre>"},{"location":"system/development/releasing/","title":"Releasing","text":"<p>ADR-00002 outlines our release strategy.</p> <p>Upon merge to <code>main</code>, releases are automatically managed and orchestrated via Github Actions, utilizing GoReleaser for building and packaging releases, Commitizen for versioning and changelog generation.</p>"},{"location":"system/development/resources/","title":"Awesome Resources","text":"<ul> <li>Awesome Go - Awesome Go repo</li> <li>Awesome Vue - Awesome Vue repo</li> <li>Awesome AZD - Awesome Azure Azd repo</li> <li>Go By Example - Various Go basics with easy to follow implementation examples</li> <li>Go Seed - Bare bones Go project with OOTB Goreleaser pipelines and useful makefile</li> <li>Go Clean Template</li> <li>Sklinkert Go-DDD - a similar DDD boilerplate in go, however it does not currently implement <code>context.Context</code>, relies on separate validated entity structs within the domain layer, and lacks much of the additional boilerplate functionality</li> </ul>"},{"location":"system/development/resources/#docs-sites","title":"Docs Sites","text":"<ul> <li>vue</li> <li>Go</li> <li>GoReleaser</li> <li>OapiCodeGen</li> <li>vite</li> <li>tailwind</li> <li>daisyui</li> <li>golang-migrate</li> <li>sqlc</li> <li>chi</li> <li>opentelemetry</li> <li>postgres</li> <li>jaeger</li> <li>docker</li> <li>docker compose</li> <li>azure azd</li> <li>azure container apps</li> <li>azure bicep</li> <li>golangci-lint</li> <li>gofumpt</li> <li>commitizen</li> <li>Make (Makefile)</li> <li>Knip</li> <li>ESLint</li> <li>mkdocs</li> <li>Material for Mkdocs</li> <li>mockery</li> <li>pnpm</li> <li>uv</li> </ul>"},{"location":"system/development/resources/#ui-design-resources","title":"UI Design Resources","text":"<ul> <li>daisyui - Many readily available pre-built components.</li> <li>TailwindFlex - A collection of free Tailwind CSS components and templates.</li> </ul>"},{"location":"system/development/testing/","title":"Testing","text":"<p>In order to ensure the quality of our codebase, we have implemented comprehensive testing strategies for both the frontend and backend components of the application.</p> <p>Test-Driven Development (TDD) is recommended as a best practice, although it is not mandatory or enforced. This approach encourages writing tests before the actual implementation, leading to more reliable and maintainable code.</p>"},{"location":"system/development/testing/#writing-tests","title":"Writing Tests","text":"<p>Tests follow the Arrange-Act-Assert (AAA) pattern to enhance readability and maintainability. This pattern involves three steps:</p> <p>Arrange: Set up the necessary preconditions and inputs. This may include creating objects, setting initial values, or configuring mocks implementations. Act: Execute the logic being tested, such as calling a function or method. Assert: Verify that the outcome is as expected.</p>"},{"location":"system/development/testing/#frontend","title":"Frontend","text":"<p>The frontend test suite consists of:</p> <ul> <li>MockServiceWorker (MSW) for API mocking</li> <li>Vitest as the test runner</li> <li>Vue Test Utils for component testing</li> </ul>"},{"location":"system/development/testing/#running-frontend-tests","title":"Running Frontend Tests","text":"<p>To run the frontend tests, use one of the following commands:</p> <pre><code># from root dir\n/&gt; make test-fe\n\n# from frontend dir\n/api/frontend/&gt; pnpm test # runs test\n\n/api/frontend/&gt; pnpm coverage # runs coverage\n</code></pre>"},{"location":"system/development/testing/#backend","title":"Backend","text":"<p>The backend test suite consists of:</p> <ul> <li>Testify for assertions and mocking</li> <li>Mockery for generating mocks</li> </ul>"},{"location":"system/development/testing/#running-backend-tests","title":"Running Backend Tests","text":"<p>To run the backend tests, use the following command:</p> <pre><code>/&gt; make test-be\n</code></pre>"},{"location":"system/development/testing/#end-to-end-e2e-testing","title":"End-to-End (e2e) Testing","text":"<p>End to End testing is implemented using Playwright with the playwright-go library.</p>"},{"location":"system/development/testing/#writing-e2e-tests","title":"Writing e2e Tests","text":"<p>End to End tests SHOULD adhere to Behavior-Driven Development practices, which emphasize focusing on the User perspective and the associated scenario a User encounters within the system.</p> <p>Behavior-Driven Development Tests should follow the Given-When-Then format:</p> <ul> <li>Given: the initial context at the beginning of the scenario, in one or more clauses;</li> <li>When: the event that triggers the scenario;</li> <li>Then: the expected outcome, in one or more clauses.</li> </ul> <p>In order to develop e2e tests, the following development flow is recommended:</p> <ul> <li> <p>Open 2 terminal sessions</p> <pre><code># Terminal 1\nmake compose\n</code></pre> </li> <li> <p>Write the associated Test</p> </li> <li> <p>Run the test locally</p> <pre><code># Terminal 2\nmake e2e\n</code></pre> </li> </ul>"},{"location":"system/development/testing/#running-e2e-tests","title":"Running e2e Tests","text":"<p>Run with docker compose to handle spinning up the application + database + e2e tests within a container</p> <pre><code>make compose-e2e\n</code></pre> <p>Run locally (assuming the app + database are already running)</p> <pre><code>make e2e\n</code></pre>"},{"location":"system/development/tools/","title":"Development Tools","text":""},{"location":"system/development/tools/#azure-developer-cli-azd","title":"Azure Developer CLI (azd)","text":"<p>Documentation: Azure Developer CLI (azd)</p>"},{"location":"system/development/tools/#commitizen","title":"Commitizen","text":"category detail Documentation Commitizen System Context Project Purpose Standardizing commit messages according to Conventional Commits Configuration .cz.yaml Usage Run <code>make commit</code> to create a commit with a standardized message"},{"location":"system/development/tools/#docker","title":"Docker","text":"category detail Documentation docker System Context Project Purpose Containerization of the application Configuration build/docker/Dockerfile Usage"},{"location":"system/development/tools/#docker-compose","title":"Docker Compose","text":"category detail Documentation docker compose System Context Project Purpose Development environment orchestration Configuration deploy/compose/ Usage <code>make compose</code>"},{"location":"system/development/tools/#eslint","title":"ESLint","text":"category detail Documentation ESLint System Context Frontend Purpose Linting for JavaScript/TypeScript code in the frontend application Configuration .eslintrc.json Usage <code>make lint-fe</code>"},{"location":"system/development/tools/#gofumpt","title":"GoFumpt","text":"category detail Documentation GoFumpt System Context Core / Backend Purpose Go code formatter, stricter than <code>gofmt</code> Configuration N/A Usage <code>make format</code>, <code>make format-be</code>"},{"location":"system/development/tools/#golangci-lint","title":"Golangci-lint","text":"category detail Documentation Golangci-lint System Context Core / Backend Purpose Go linting Configuration .golangci.yml Usage <code>make lint</code>, <code>make lint-be</code>"},{"location":"system/development/tools/#golang-migrate","title":"Golang-Migrate","text":"category detail Documentation golang-migrate System Context Core / Backend Purpose Database schema migrations Configuration migrations/ Usage"},{"location":"system/development/tools/#goreleaser","title":"GoReleaser","text":"category detail Documentation GoReleaser System Context Core / Backend Purpose Automation and orchestration of project releases Configuration .goreleaser.yml Usage"},{"location":"system/development/tools/#knip","title":"Knip","text":"category detail Documentation Knip System Context Frontend Purpose Identifying unused dependencies in the frontend application Configuration knip.config.js Usage <code>make deps</code>, <code>pnpm declutter</code>"},{"location":"system/development/tools/#make","title":"Make","text":"category detail Documentation Make (Makefile) System Context Project Purpose Automation &amp; Orchestration of common tasks and commands for project development Configuration Makefile Usage <code>make help</code> - displays all available make commands"},{"location":"system/development/tools/#mockery","title":"Mockery","text":"category detail Documentation mockery System Context Core / Backend Purpose Mock generation for Go interfaces Configuration mockery.yml Usage Run <code>make mock</code> to generate mocks for the Go interfaces"},{"location":"system/development/tools/#mkdocs-material-for-mkdocs","title":"MkDocs + Material for MkDocs","text":"category detail Documentation mkdocs, Material for Mkdocs System Context Documentation Purpose Documentation site generation and theming Configuration mkdocs.yml Usage Run <code>make docs</code> to build the documentation site"},{"location":"system/development/tools/#oapicodegen","title":"OapiCodeGen","text":"category detail Documentation OapiCodeGen System Context Core / Backend Purpose Generating Go server and client code from OpenAPI 3.0 specifications Configuration cfg.yaml Usage <code>make gen-api-be</code>"},{"location":"system/development/tools/#openapi-generator-cli","title":"OpenAPI-Generator-Cli","text":"category detail Documentation OpenAPI-Generator-Cli System Context Frontend Purpose Generation of the typescript API client library to enable the consumption of REST APIs from OpenAPI specifications Configuration openapi-generator-config.json Usage <code>make gen-api-fe</code>"},{"location":"system/development/tools/#playwright-go","title":"Playwright-Go","text":"category detail Documentation Playwright-Go System Context Core / Backend + Frontend Purpose Core Library for development of end to end tests Configuration Usage Run <code>make compose-e2e</code> or <code>make e2e</code> to run e2e tests"},{"location":"system/development/tools/#prettier","title":"Prettier","text":"category detail Documentation Prettier System Context Frontend Purpose Code formatter for consistent code style in the frontend application Configuration prettier.config.js Usage <code>make format-fe</code>"},{"location":"system/development/tools/#pnpm","title":"PNPM","text":"category detail Documentation pnpm System Context Frontend Purpose Package management for the frontend application Configuration package.json Usage"},{"location":"system/development/tools/#sqlc","title":"SQLC","text":"category detail Documentation sqlc System Context Core / Backend Purpose Generation of go code for database interaction from sql queries Configuration .sqlc.yaml Usage"},{"location":"system/development/tools/#uv","title":"UV","text":"category detail Documentation uv System Context Documentation Purpose Python environment and package management for the documentation site Configuration pyproject.toml Usage"},{"location":"system/development/tools/#vite","title":"Vite","text":"category detail Documentation vite System Context Frontend Purpose build tool for frontend Configuration vite.config.ts Usage"},{"location":"system/development/tools/#vitest","title":"Vitest","text":"category detail Documentation Vitest System Context Frontend Purpose Testing framework for the frontend application Configuration vite.config.ts Usage <code>make test-fe</code>"},{"location":"system/development/versioning/","title":"Versioning","text":"<p>We adhere to Semantic Versioning (SemVer)</p>"},{"location":"system/domain_modelling/","title":"Domain Modelling","text":"<p>Domain modelling enables us to design our solution across each aspect of Domain-Driven Design practices. For reference material and further information refer to DDD Crew Domain Modelling.</p>"},{"location":"system/domain_modelling/#understand","title":"Understand","text":"<p>Align our focus with the organisation's business model, the needs of its users, and its short, medium, and long-term goals.</p> <p></p>"},{"location":"system/domain_modelling/#discover","title":"Discover","text":"<p>Discover the domain visually and collaboratively.</p> <p></p>"},{"location":"system/domain_modelling/#decompose","title":"Decompose","text":"<p>Decompose the domain into sub-domains - loosely-coupled parts of the domain.</p> <p>Independent Service Heuristics</p>"},{"location":"system/domain_modelling/#strategize","title":"Strategize","text":"<p>Strategically map out your sub-domains to identify core domains: the parts of the domain which have the greatest potential for business differentiation or strategic significance.</p> <p></p>"},{"location":"system/domain_modelling/#connect","title":"Connect","text":"<p>Connect the sub-domains into a loosely-coupled architecture which fulfills end-to-end business use-cases.</p> <p></p>"},{"location":"system/domain_modelling/#organise","title":"Organise","text":"<p>Organise autonomous teams that are optimised for fast flow and aligned with context boundaries.</p> <p></p>"},{"location":"system/domain_modelling/#define","title":"Define","text":"<p>Define the roles and responsibilities of each bounded context.</p> <p></p>"},{"location":"system/domain_modelling/#code","title":"Code","text":"<p>Code the domain model.</p> <p></p>"},{"location":"system/domain_modelling/0_kata_overview/","title":"Making the Grade: Kata Overview","text":"<p>source: https://www.architecturalkatas.com/kata.html?kata=MakeTheGrade.json</p>"},{"location":"system/domain_modelling/0_kata_overview/#kata-overview","title":"Kata Overview","text":"<p>A very large and populous state would like a new system to support standardized testing across all public school systems grades 3-12.</p>"},{"location":"system/domain_modelling/0_kata_overview/#users","title":"Users","text":"<ul> <li>40,000+ students</li> <li>2000 graders</li> <li>50 administrators</li> </ul>"},{"location":"system/domain_modelling/0_kata_overview/#requirements","title":"Requirements","text":"<ul> <li> <p>Students will only be able to use the application within testing centers around the state, most of these will be in the schools, but not all of them</p> </li> <li> <p>Students should be able to take a test, and the results eventually consolidated to a single location representing all of the test scores across the state (by school, teacher, and student).</p> </li> <li> <p>Tests will be multiple choice, short answer, and essay.</p> </li> <li> <p>The system should have a reporting system to know which students have taken the tests and what score they received.</p> </li> <li> <p>Short answer and essay questions will be manually graded by teachers, who will then add the essay grades to the system.</p> </li> </ul>"},{"location":"system/domain_modelling/0_kata_overview/#additional-context","title":"Additional Context","text":"<p>A change approval processes involving three different government agencies is required for changes to the way student grades are kept to ensure security; The state does not own its hosting center, but outsources it to a third party; Project must defend its budget each fiscal year.</p>"},{"location":"system/domain_modelling/0_kata_overview/#assumptions","title":"Assumptions","text":"<p>The following assumptions have been made regarding the given kata.</p> <ul> <li> <p>Initially, the complexity of Standardized Tests will remain fairly static, with an assumed 1:1 ratio of Standardized Test and its associtated questions and content : Student Grade Level.</p> </li> <li> <p>A standardized Test consists of approximately 50 questions</p> </li> <li> <p>A standardized Test has a time limit of 1 hour.</p> </li> <li> <p>On Average, during the taking of a Standardized Test, each Student will spend approximately 1 minute answering each question</p> </li> <li> <p>Students / Grade Level are fairly evenly distributed, meaning there are roughly 4,000+ students / grade level</p> </li> <li> <p>Standardized Tests are taken on different days according to Grade Level</p> </li> <li> <p>All students across the state take a given Standardized Test for their grade level on the same day and at roughly the same time.</p> </li> </ul>"},{"location":"system/domain_modelling/0_kata_overview/#derived-technical-requirements","title":"Derived Technical Requirements","text":"<p>The following technical requirements have been derived according to the given business requirements and assumptions made.</p> <ul> <li>The system will have significant peaks on days where standardized tests are being given, with much lower interaction and usage on days where standardized tests are not being given</li> <li>The System must be able to handle up to ~4k requests per minute during peak days in which standardized tests are being given</li> <li>40k students / 10 grade levels / 1 answer per minute = ~4k req/min</li> </ul>"},{"location":"system/domain_modelling/1_kata_understand/","title":"Making the Grade: Understand","text":""},{"location":"system/domain_modelling/1_kata_understand/#making-the-grade-business-model-canvas","title":"Making The Grade: Business Model Canvas","text":"<p>Here, we have developed a Business Model Canvas to address and support the <code>Making the Grade</code> architecture kata</p>"},{"location":"system/domain_modelling/2_kata_discover/","title":"Making the Grade: Discover","text":"<p>Discover the domain visually and collaboratively.</p> <p></p>"},{"location":"system/domain_modelling/2_kata_discover/#observations","title":"Observations","text":"<p>Through the discovery process, we find that we have a fundamental challenge in aligning on developing an ubiquitus language:</p> <ul> <li>in the business context, the terminology <code>test</code> / <code>testing</code> refers to the taking of an academic exam by grade school students to determine their academic skills</li> <li>in the software context, the terminology <code>test</code> / <code>testing</code> typically refers to tools and practices to verify functionality of software systems</li> </ul> <p>While at surface level this sounds like it could be a minor detail or a non-issue, it highlights a key challenge in aligning and communicating the business + technology challenges.</p> <p>For example, let's assume we run into a situation where a business stakeholder and the software product owner are discussing an issue with the system.</p> <p>Product Owner: \"we ran into some issues with testing that caused the outage\"</p> <p>Business Owner: \"what does that mean? are the tests gone?\"</p> <p>Product Owner: \"oh no, they're still there, we'll just have to redo them\"</p> <p>Business Stakeholder: \"well that's going to cause some major issues, do we have any alternatives?\"</p> <p>Product Owner: \"hmm, let me talk to the team and get back to you on that\"</p> <p>The Business Stakeholder, then notifies all school administrators across the state that standardized testing will have to be redone. Administrators start preparing various forms of communications to share with teachers, students, parents of students, etc.</p> <p>Meanwhile, the Product Owner asks the development team if there are any alternate solutions to the challenges they faced with the integration tests that were missed, resuling in an outage. The development team informs the PO that they've already merged the PR addressing the missed tests, in addition to correcting the root cause of the bug.</p> <p>A few days pass and the PO and Business Stakeholder meet again. The PO is prepared to provide an update to the business stakeholder regarding the missing integration tests and resolution of the bug that caused the outage, while the business stakeholder is prepared to talk about how they're going to have students retake their standardized tests.</p> <p>This very simplified example is very realistic in the sense of terms how people interpret words and their meaning in the context they perform their job and what they understand the term to mean in their context. The challenge and concept of developing a Ubiquitous Language, coined particularly to highlight the importance of developing a shared understanding between developers and users, is prevelant in various other business, technical, academic, contexts and something that most people can most likely relate to even in their standard day-to-day lives.</p>"},{"location":"system/domain_modelling/2_kata_discover/#decisions","title":"Decisions","text":"<ul> <li>the terms <code>Exam</code>, <code>Examination</code>, will serve as common terminology to describe Standardized Tests which are taken by gradeschool students</li> </ul>"},{"location":"system/domain_modelling/3_kata_decompose/","title":"Making the Grade: Decompose","text":"<p>Decompose the domain into sub-domains - loosely-coupled parts of the domain.</p> <p></p> <p>In reviewing the Domain Story defined during the Discover phase, we identify the boundaries around parts of the system that contain commonality amongst types of entities and their attributes</p>"},{"location":"system/domain_modelling/3_kata_decompose/#applying-independent-service-heuristics","title":"Applying Independent Service Heuristics","text":"<p>Next, we'll apply the concept of Independent Service Heuristics to our various subdomains / bounded contexts to help us validate and/or identify any gaps in our defined subdomains.</p>"},{"location":"system/domain_modelling/3_kata_decompose/#grading","title":"Grading","text":"<ol> <li>Sense-check: Could it make any logical sense to offer this thing \"as a service\"?     Yes</li> <li>Brand: Could you imagine this thing branded as a public cloud service (like AvocadoOnline.com \ud83e\udd51)?     Yes</li> <li>Revenue/Customers: Could this thing be managed as a viable cloud service in terms of revenue and customers?     Yes</li> <li>Cost tracking: Could the organisation currently track costs and investment in this thing separately from similar things?     Yes</li> <li>Data: Is it possible to define clearly the input data (from other sources) that this thing needs?     Yes</li> <li>User Personas: Could this thing have a small/well-defined set of user types or customers (user personas)?     Yes</li> <li>Teams: Could a team or set of teams effectively build and operate a service based on this thing?     Yes</li> <li>Dependencies: Would this team be able to act independently of other teams for the majority of the time to achieve their objectives?     Yes</li> <li>Impact/Value: Would the scope of this thing provide a team with an impactful and engaging challenge?     Yes</li> <li>Product Decisions: Would the team working on this thing be able to \"own\" their own product roadmap and the product direction?     Yes</li> </ol>"},{"location":"system/domain_modelling/3_kata_decompose/#examination","title":"Examination","text":"<ol> <li>Sense-check: Could it make any logical sense to offer this thing \"as a service\"?     Yes</li> <li>Brand: Could you imagine this thing branded as a public cloud service (like AvocadoOnline.com \ud83e\udd51)?     Yes</li> <li>Revenue/Customers: Could this thing be managed as a viable cloud service in terms of revenue and customers?     Yes</li> <li>Cost tracking: Could the organisation currently track costs and investment in this thing separately from similar things?     Yes</li> <li>Data: Is it possible to define clearly the input data (from other sources) that this thing needs?     Yes</li> <li>User Personas: Could this thing have a small/well-defined set of user types or customers (user personas)?     Yes</li> <li>Teams: Could a team or set of teams effectively build and operate a service based on this thing?     Yes</li> <li>Dependencies: Would this team be able to act independently of other teams for the majority of the time to achieve their objectives?     Yes</li> <li>Impact/Value: Would the scope of this thing provide a team with an impactful and engaging challenge?     Yes</li> <li>Product Decisions: Would the team working on this thing be able to \"own\" their own product roadmap and the product direction?     Yes</li> </ol>"},{"location":"system/domain_modelling/3_kata_decompose/#exam-library","title":"Exam Library","text":"<ol> <li>Sense-check: Could it make any logical sense to offer this thing \"as a service\"?     Yes</li> <li>Brand: Could you imagine this thing branded as a public cloud service (like AvocadoOnline.com \ud83e\udd51)?     Yes</li> <li>Revenue/Customers: Could this thing be managed as a viable cloud service in terms of revenue and customers?     Yes</li> <li>Cost tracking: Could the organisation currently track costs and investment in this thing separately from similar things?     Yes</li> <li>Data: Is it possible to define clearly the input data (from other sources) that this thing needs?     Yes</li> <li>User Personas: Could this thing have a small/well-defined set of user types or customers (user personas)?     Yes</li> <li>Teams: Could a team or set of teams effectively build and operate a service based on this thing?     Yes</li> <li>Dependencies: Would this team be able to act independently of other teams for the majority of the time to achieve their objectives?     Yes</li> <li>Impact/Value: Would the scope of this thing provide a team with an impactful and engaging challenge?     Yes</li> <li>Product Decisions: Would the team working on this thing be able to \"own\" their own product roadmap and the product direction?     Yes</li> </ol>"},{"location":"system/domain_modelling/3_kata_decompose/#identity-and-access-management","title":"Identity and Access Management","text":"<ol> <li>Sense-check: Could it make any logical sense to offer this thing \"as a service\"?     Yes</li> <li>Brand: Could you imagine this thing branded as a public cloud service (like AvocadoOnline.com \ud83e\udd51)?     Yes</li> <li>Revenue/Customers: Could this thing be managed as a viable cloud service in terms of revenue and customers?     Yes</li> <li>Cost tracking: Could the organisation currently track costs and investment in this thing separately from similar things?     Yes</li> <li>Data: Is it possible to define clearly the input data (from other sources) that this thing needs?     Yes</li> <li>User Personas: Could this thing have a small/well-defined set of user types or customers (user personas)?     Yes</li> <li>Teams: Could a team or set of teams effectively build and operate a service based on this thing?     Yes</li> <li>Dependencies: Would this team be able to act independently of other teams for the majority of the time to achieve their objectives?     Yes</li> <li>Impact/Value: Would the scope of this thing provide a team with an impactful and engaging challenge?     Yes</li> <li>Product Decisions: Would the team working on this thing be able to \"own\" their own product roadmap and the product direction?     Yes</li> </ol>"},{"location":"system/domain_modelling/3_kata_decompose/#reporting","title":"Reporting","text":"<ol> <li>Sense-check: Could it make any logical sense to offer this thing \"as a service\"?     Yes</li> <li>Brand: Could you imagine this thing branded as a public cloud service (like AvocadoOnline.com \ud83e\udd51)?     Yes</li> <li>Revenue/Customers: Could this thing be managed as a viable cloud service in terms of revenue and customers?     Yes</li> <li>Cost tracking: Could the organisation currently track costs and investment in this thing separately from similar things?     Yes</li> <li>Data: Is it possible to define clearly the input data (from other sources) that this thing needs?     Yes</li> <li>User Personas: Could this thing have a small/well-defined set of user types or customers (user personas)?     Yes</li> <li>Teams: Could a team or set of teams effectively build and operate a service based on this thing?     Yes</li> <li>Dependencies: Would this team be able to act independently of other teams for the majority of the time to achieve their objectives?     Yes</li> <li>Impact/Value: Would the scope of this thing provide a team with an impactful and engaging challenge?     Yes</li> <li>Product Decisions: Would the team working on this thing be able to \"own\" their own product roadmap and the product direction?     Yes</li> </ol>"},{"location":"system/domain_modelling/4_kata_strategize/","title":"Making the Grade: Strategize","text":"<p>Strategically map out your sub-domains to identify core domains: the parts of the domain which have the greatest potential for business differentiation or strategic significance.</p>"},{"location":"system/domain_modelling/4_kata_strategize/#core-domain-chart","title":"Core Domain Chart","text":""},{"location":"system/domain_modelling/4_kata_strategize/#subdomain-definitions","title":"Subdomain Definitions","text":""},{"location":"system/domain_modelling/4_kata_strategize/#core-subdomains","title":"Core Subdomains","text":"<ul> <li>Examination: handles taking of standardized tests. We have identified Examination to be a <code>Core</code> domain, due to the fact that it has a high level of, and is the primary point of interaction, for Students. It is imperative that we provide this functionality and have the ability to customize and control examination subdomain.</li> <li>Grading: handles grading of standardized tests. Given the fact that many of the exams will contain short and long answer questions which are subjectively graded by graders, and without this subdomain, we lose critical functinality of the business requirements of our system.</li> <li>Reporting: handles generation and management of reports. Initially thought to be a supporting subdomain, we have further come to an understanding that the potential for insights regarding statistical analysis, trends, identification of weaknesses across school and student demographics, provides a significant amount of value to the business (state), and therefore requires a level of custom development in order to provide relevant and differentiated reports.</li> </ul>"},{"location":"system/domain_modelling/4_kata_strategize/#supporting-subdomains","title":"Supporting Subdomains","text":"<ul> <li>Exam Library: manages catalog of tests available within the system. This subdomain has a possibilty to become more strategic and core to our business, however, the differentiator is moreso the breadth of content and less so the functionality of the subdomain from the end user perspective. For the time being, we are solving for a small number of variations in exam content</li> </ul>"},{"location":"system/domain_modelling/4_kata_strategize/#generic-subdomains","title":"Generic Subdomains","text":"<ul> <li>Identity and Access Management: handles authentication, authorization, and management of user profiles. User Identity and Access Management is a commodity capability with a variety of toolsets available to developers. While it is technically required to provide necessary functionality of our system, it does not provide value to our user groups, and is not considered to be core business differentiator to our business.</li> </ul>"},{"location":"system/domain_modelling/4_kata_strategize/#wardley-mapping","title":"Wardley Mapping","text":""},{"location":"system/domain_modelling/5_kata_connect/","title":"Making the Grade: Connect","text":"<p>Connect the sub-domains into a loosely-coupled architecture which fulfills end-to-end business use-cases.</p>"},{"location":"system/domain_modelling/5_kata_connect/#student-takes-exam","title":"Student Takes Exam","text":""},{"location":"system/domain_modelling/5_kata_connect/#grader-grades-exam","title":"Grader Grades Exam","text":""},{"location":"system/domain_modelling/5_kata_connect/#administrator-views-report","title":"Administrator Views Report","text":""},{"location":"system/domain_modelling/6_kata_organize/","title":"Making the Grade: Organize","text":"<p>Organize autonomous teams that are optimized for fast flow and aligned with context boundaries.</p>"},{"location":"system/domain_modelling/6_kata_organize/#team-topology","title":"Team Topology","text":"<p>We've outlined our team topology to optimize for fast flow, enabling autonomous teams to deliver value quickly.</p>"},{"location":"system/domain_modelling/6_kata_organize/#enabling-teams","title":"Enabling Teams","text":"<ul> <li>Product Architecture Team: Provides architectural guidance, ensures adherence to standards, and supports stream-aligned teams in delivering high-quality solutions.</li> </ul>"},{"location":"system/domain_modelling/6_kata_organize/#complicated-subsystem-teams","title":"Complicated-Subsystem Teams","text":"<ul> <li>None</li> </ul>"},{"location":"system/domain_modelling/6_kata_organize/#stream-aligned-teams","title":"Stream-aligned Teams","text":"<ul> <li>Exam Library Team: Frontend, Backend/core domain, and Database for Exam Library bounded context.</li> <li>Examination Team: Frontend, Backend/core domain, and Database for Examination bounded context.</li> <li>Grading Team: Frontend, Backend/core domain, and Database for Grading bounded context.</li> <li>Reporting Team: Frontend, Backend/core domain, and Database for Reporting bounded context.</li> <li>Identity and Access Management Team: Frontend, Backend/core domain, and Database for Identity and Access Management bounded context.</li> </ul>"},{"location":"system/domain_modelling/6_kata_organize/#platform-teams","title":"Platform Teams","text":"<ul> <li>The Go-Full Platform Team: Everything outside of bounded context modules. The go-full platform team manages infrastructure, shared services, and cross-cutting concerns to support stream-aligned teams.</li> </ul>"},{"location":"system/domain_modelling/6_kata_organize/#team-topology-in-action-alignment-to-code-ownership","title":"Team Topology In Action: Alignment to Code Ownership","text":"<p>In order to reinforce and provide a realistic example of our team topology, we've aligned our code ownership structure accordingly.</p>"},{"location":"system/domain_modelling/6_kata_organize/#why-this-works","title":"Why This Works","text":"<p>Scaling software delivery requires more than just technical solutions; it demands an organizational structure that promotes autonomy and fast flow. By organizing teams around bounded contexts and ensuring clear ownership, we enable teams to focus on delivering value without unnecessary dependencies or bottlenecks.</p> <p>As bounded contexts evolve, and either become more complex or do not require as much dedicated focus, we can adapt our team structures accordingly.</p>"},{"location":"system/domain_modelling/6_kata_organize/#less-effective-alternatives","title":"Less Effective Alternatives","text":"<ul> <li>Tool-specific Teams: Organizing teams around specific tools or technologies can create silos, stifle innovation, stall skill development, and hinder collaboration, as teams may become too focused on their specific tool, treating their tools as hammers looking constantly looking for nails, rather than focusing on the overall goals of the business / customer / product.</li> <li>Technical Domain Teams: While technical domain teams can provide deep expertise, they may struggle to deliver end-to-end value without strong collaboration with other teams, leading to delays and misalignment with business objectives. Its common that technical domain teams become bottlenecks, as other teams must wait for their specialized knowledge to complete tasks.</li> <li>Feature Teams Without Context Boundaries: While feature teams can be effective, without clear context boundaries, they may face challenges in managing dependencies and ensuring consistent quality across the system. This can lead to duplicated efforts and misaligned priorities, as teams may not have a holistic view of the system.</li> </ul>"},{"location":"system/domain_modelling/7_kata_define/","title":"Making the Grade: Define","text":"<p>Define the roles and responsibilities of each bounded context.</p>"},{"location":"system/domain_modelling/7_kata_define/#exam-library-bounded-context","title":"Exam Library Bounded Context","text":""},{"location":"system/domain_modelling/7_kata_define/#examination-bounded-context","title":"Examination Bounded Context","text":""},{"location":"system/domain_modelling/7_kata_define/#grading-bounded-context","title":"Grading Bounded Context","text":""},{"location":"system/domain_modelling/7_kata_define/#identity-and-access-management-bounded-context","title":"Identity and Access Management Bounded Context","text":""},{"location":"system/domain_modelling/7_kata_define/#reporting-bounded-context","title":"Reporting Bounded Context","text":""},{"location":"system/domain_modelling/8_kata_code/","title":"Making the Grade: Code","text":"<p>Code the domain model.</p>"},{"location":"system/domain_modelling/8_kata_code/#examination","title":"Examination","text":""},{"location":"system/domain_modelling/8_kata_code/#exam-library","title":"Exam Library","text":""},{"location":"system/domain_modelling/8_kata_code/#reporting","title":"Reporting","text":""},{"location":"system/domain_modelling/8_kata_code/#grading","title":"Grading","text":""},{"location":"system/domain_modelling/8_kata_code/#identity-and-access-management","title":"Identity and Access Management","text":""},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/","title":"Aggregate design canvas","text":""},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#aggrgate-design-canvas","title":"Aggrgate Design Canvas","text":"<p>Reference: https://github.com/ddd-crew/aggregate-design-canvas/tree/master</p>"},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#bounded-context","title":"[Bounded Context]","text":""},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#1-name","title":"1. Name","text":"<p>Give your aggregate a good name. In some domains it makes sense to include as part of the name the length of a cycle, or some other indication of the life span of the aggregate.</p>"},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#2-description","title":"2. Description","text":"<p>Summarise the main responsibilities and purpose of the aggregate. It\u2019s a good idea to include the reasons why such boundaries were chosen and tradeoffs that were made compared to other designs.</p>"},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#3-state-transitions","title":"3. State Transitions","text":"<p>Usually the aggregate goes through explicit state transitions, that impact the way it can be interacted with. Too many transitions might indicate that process boundaries weren't modelled properly and can be split. Very naive / simple transitions might indicate that the aggregate is anaemic and that logic was pushed out to services. In this section of the canvas list the possible states or draw a small transition diagram. </p>"},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#4-enforced-invariants","title":"4. Enforced Invariants","text":""},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#5-corrective-policies","title":"5. Corrective Policies","text":"<p>One of the main jobs of the aggregate is to enforce business invariants. These invariants protect business logic. Listing the main ones in this section will make sure that you agree on the responsibilities that the aggregate has. A large number of enforced invariants can indicate high local complexity of the aggregate implementation.</p> <p>If you decide to change the boundaries of the aggregate and relax some of the invariants (for example to reduce the chance of concurrency conflict), then some extra business logic might be required to correct some of the inconsistencies. In the context of this canvas, we call this logic corrective policies. A large number of such policies might indicate that the business logic was pushed outside of the aggregate, which can increase the complexity of implementation.</p> <p>Listing on the canvas both Invariants and Corrective Policies will make design trade-offs explicit and will help you decide whether the boundaries you decided on are useful or not.</p>"},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#6-handled-commands-7-created-events","title":"6. Handled Commands &amp; 7. Created Events","text":"<p>In this section you list all the commands that the aggregate is capable of handling and all events that will be created as a result. It might be a good idea to create connectors between them in order to validate that you are not missing any of the building blocks.</p>"},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#8-throughput","title":"8. Throughput","text":"<p>The goal of this section is to estimate how likely a single aggregate instance is going to be involved in concurrency conflicts (when two or more competing callers try to make changes at the same time). For each metric estimate the average and maximum - it will help you to reason about the outliers as they often drive the boundary reevaluation.</p> <p>The Command handling rate metric describes the rate at which the aggregate is processing new commands. On the other hand the Total number of clients says how many clients are likely to issue these commands.</p> <p>To give you an example - if an aggregate models a basket on the website then it\u2019s likely there will be only one client issuing commands to this basket. If we compare it to an aggregate that models a conference booking system then it\u2019s likely we are going to have tens or hundreds of clients trying to book tickets.</p>"},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#aggregate-concurrency-conflict-chance-evaluation-chart","title":"Aggregate concurrency conflict chance evaluation chart","text":"<p>Putting these metrics on a graph will give you a rough estimate of a Concurrency conflict chance, which is what we are ultimately looking for. Plotting both Avg and Max for multiple alternatives will allow you to explicitly talk about the throughput tradeoffs. Generally speaking, aiming for a small chance of conflict will deliver better customer experience, but will also increase the complexity of implementation. Or if we put it in a different way: bigger aggregates will have higher chance of concurrency conflict, but less policies to correct data.</p>"},{"location":"system/domain_modelling/_templates/aggregate_design_canvas/#9-size","title":"9. Size","text":"<p>The last section of the canvas will help you estimate the hypothetical size of the aggregate. In this case the size itself is being measured in the number of events per aggregate instance. Depending on how you model the domain, the events might end up being fine or coarse grained, so the size of the events will also play a role. </p> <p>E.g. a <code>OrderCreated</code> event could have multiple <code>LineItems</code> as part of the event, or model these line items as separate <code>LineItemAdded</code> events. In case of coarse grained events, the overall size of the aggregate will be bigger, even if the number of events is small.</p> <p>The Event growth rate metric should estimate how many events are appended to a single aggregate instance. The Lifetime of an instance will tell us how long the instance is going to live and as a consequence how many events will be accumulated and fetched when we need to process a new command.</p>"},{"location":"system/domain_modelling/_templates/independent_service_heuristics/","title":"Independent Service Heuristics Checklist","text":"<p>source: https://github.com/TeamTopologies/Independent-Service-Heuristics/blob/main/README.md</p> <ol> <li>Sense-check: Could it make any logical sense to offer this thing \"as a service\"?<ul> <li>Is this thing independent enough?</li> <li>Would consumers understand or value it?</li> <li>Would it simplify execution?</li> </ul> </li> <li>Brand: Could you imagine this thing branded as a public cloud service (like AvocadoOnline.com \ud83e\udd51)?<ul> <li>Would it be a viable business (or \"micro-business\") or service?</li> <li>Would it be a compelling offering?</li> <li>Could a marketing campaign be convincing?</li> </ul> </li> <li>Revenue/Customers: Could this thing be managed as a viable cloud service in terms of revenue and customers?<ul> <li>Would it be a viable service with a paid offering?</li> <li>Would it bring recurring revenue with subscription plans?</li> <li>Is there a clearly-defined customer base or segment?</li> </ul> </li> <li>Cost tracking: Could the organisation currently track costs and investment in this thing separately from similar things?<ul> <li>Are the full costs of running this thing transparent or possible to discover considering infrastructure costs, data storage costs, data transfer costs, licence costs, etc.?</li> <li>Is this thing fairly separate, disconnected from other things in the organisation?</li> <li>Does the organisation track this separately?</li> </ul> </li> <li>Data: Is it possible to define clearly the input data (from other sources) that this thing needs?<ul> <li>Is the thing fairly independent from any data sources?</li> <li>Are the sources internal (under our control, not external)?</li> <li>Is the input data clean (not messy)?</li> <li>Is the input data provided in a self-service way? Can the team consume the input data \"as a service\"?</li> </ul> </li> <li>User Personas: Could this thing have a small/well-defined set of user types or customers (user personas)?<ul> <li>Is the thing meeting specific user needs?</li> <li>Do we know (or can we easily articulate) these user types and their needs?</li> </ul> </li> <li>Teams: Could a team or set of teams effectively build and operate a service based on this thing?<ul> <li>Would the cognitive load (breadth of topics/context switching) be bounded to help the team focus and succeed?</li> <li>Would significant infrastructure or other platform abstractions be unnecessary?</li> </ul> </li> <li>Dependencies: Would this team be able to act independently of other teams for the majority of the time to achieve their objectives?<ul> <li>Is this thing logically independent from other things?</li> <li>Could the team \"self-serve\" dependencies in a non-blocking manner from a platform?</li> </ul> </li> <li>Impact/Value: Would the scope of this thing provide a team with an impactful and engaging challenge?<ul> <li>Is the scope big enough to provide an impact? Would the scope be engaging for talented people?</li> <li>Is there sufficient value to customers and the organization that the value would be clearly recognized?</li> </ul> </li> <li>Product Decisions: Would the team working on this thing be able to \"own\" their own product roadmap and the product direction?<ul> <li>Does this thing provide discrete value in a well-defined sphere of execution?</li> <li>Can the team define their own roadmap based on what they discover is best for the product and its users (so that the team is not driven by the requirements and priorities of other teams)?</li> </ul> </li> </ol>"},{"location":"system/domain_modelling/_templates/independent_service_heuristics/#further-considerations","title":"Further considerations","text":"<ul> <li>Vocabulary: is the vocabulary consistent between different parts of the system or different business domains? If not (if the same word means something different in different areas), then there may need to be two different services or systems.</li> <li>Phases: does one part of a system deal with an earlier or later phase in processing? This may also represent a good boundary.</li> <li>Wardley Maps: could the capability or service be outsourced to a SaaS Product or Commodity provider? Will it likely be outsource-able soon? If so, it's a candidate for splitting off as a separate service in preparation for possible outsourcing to a Product or Commodity provider.</li> <li>Risk: what is the cost of risk of splitting this capability or service? Could something go wrong?</li> </ul>"},{"location":"system/domain_modelling/_templates/independent_service_heuristics/#detailed-considerations","title":"Detailed considerations","text":"<ul> <li>Loose coupling: Does this 'thing' make sense to independently migrate / deploy in the public cloud independent of related 'things'?</li> <li>Tight coupling: Do you have any dependencies on vendor / 3rd party software that prevents scaling if demand increases ?</li> <li>Commercial opportunity: Is there demand for this 'thing' outside of the context of its current usage? Could this be used more broadly within your organization or to different customer segments?</li> <li>Data governance: Does this 'thing' act as a master or authoritative source for key static / reference / client data?</li> <li>Interface contracts: Do you have versioned interface contracts and the ability to deploy new versions without impacting existing 'customers' (consumers)?</li> <li>Resilience / scalability: as demand for your 'thing' scales do you have a linear increase in demand for new capacity / availability (including geographical regions)?</li> <li>Skills liquidity: consider the skills mix in the teams. Can the teams each own their service/system after the split?</li> <li>Anti-pattern - data coupling: Does your 'thing' depend upon tight coupling / specific vendor drivers or use things like DB Links rather than through a managed versioned API?</li> <li>Anti-pattern - release coordination: Do you upstream / downstream producers / consumers need your 'thing' to coordinate a release (e.g. release train) or can they release independently as frequently as they need to?</li> </ul>"}]}